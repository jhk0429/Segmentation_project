{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZgPEymw9njoY"
   },
   "outputs": [],
   "source": [
    "#path = 'saved_model_1012_hole_Adam_40_0.0001' \n",
    "path = 'saved_model_1012_hole_RMSprop_50_0.0001' #Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXRm-jLtmzga",
    "outputId": "f7f57301-6e86-4cf3-deb6-f43f81a2829f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import segmentation_models as sm\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "KLDykGNHmkjU",
    "outputId": "9da2feff-35eb-478d-d052-7c9b2807464a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n  raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\\n\""
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (624,672)\n",
    "\n",
    "CROP_SIZE = [tf.cast((2048/2 - 360), tf.int32), tf.cast((2448/2 - 360), tf.int32),624,672] #x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r0bNqPN0sR-1"
   },
   "outputs": [],
   "source": [
    "def display(display_list, idx=None, only_inference=False, fig_size=15):\n",
    "    \"\"\"\n",
    "    \"only_inference\" = True creates sample of inferenced image PNG file.\n",
    "    \"\"\"\n",
    "    if only_inference:\n",
    "        a = np.array(display_list)\n",
    "        a = a.astype(np.float32) * 255.0\n",
    "\n",
    "        cv2.imwrite(\"EX{}.png\".format(idx), cv2.cvtColor(a, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    else:\n",
    "        plt.figure(figsize=(fig_size,fig_size))\n",
    "        title = ['Ground Truth Mask', 'Pushed', 'Stamped']\n",
    "\n",
    "        for i in range(len(display_list)):\n",
    "            plt.subplot(1, len(display_list), i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l5OoNvjhsSYQ"
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask, num=0):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[num]\n",
    "\n",
    "def show_predictions(test_mode=False, x=None,y=None, num=1):\n",
    "    if test_mode:\n",
    "        print(\"In testing Mode...\")\n",
    "        for i in range(num):\n",
    "            pred_mask = model.predict(x, batch_size=1)\n",
    "            display([x[i], y[i], create_mask(pred_mask, num=i)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_and_count(img, contours, label = '', draw_type = 'contour', show=True):\n",
    "    # img : original image\n",
    "    # contours: Contours found from opencv code\n",
    "    assert label in ['push', 'stamp', 'hole'], \"label must be either 'push' or 'stamp'\"\n",
    "    assert draw_type in ['bbox', 'contour'], \"draw type must be either 'bbox' or 'contour'\"\n",
    "    \n",
    "    if label=='push': val = 220\n",
    "    if label=='stamp': val = 150\n",
    "    if label=='hole' : val = 1000\n",
    "        \n",
    "    count = 0\n",
    "    area = []\n",
    "    width_height = []\n",
    "    \n",
    "    for idx, cnt in enumerate(contours):\n",
    "        a = cv2.contourArea(cnt)\n",
    "        if a < val:\n",
    "            continue\n",
    "        \n",
    "        area.append(a)\n",
    "        count += 1\n",
    "        \n",
    "        if draw_type == 'bbox':\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(125,125,0),2)\n",
    "            width_height.append([w,h])\n",
    "            print(\"{} #{} has width of {} and height of {}\".format(label, idx, w, h))\n",
    "            \n",
    "        elif draw_type == 'contour':\n",
    "            cv2.drawContours(img, [cnt], 0, (125, 125, 0), 2) \n",
    "            \n",
    "    if show:        \n",
    "        display([img], fig_size=8)\n",
    "        print(\"{} {} found. Area: {}\".format(count,label,area))\n",
    "\n",
    "        \n",
    "    return img, area, width_height, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twqjJGlpgxFv",
    "outputId": "c47d45d0-441e-4991-97b0-01f0e2b1108e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0, 0.0, 0.0], 1: array([0., 0., 1.]), 2: [0.0, 0.0, 0.0], 3: [0.0, 0.0, 0.0], 4: array([0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "mask = imread('JR_dataset/train/silver_ng/new_gt_mask/높음2__분리막 눌림_은색.png') #2048 x 2448\n",
    "\n",
    "colors = np.unique(tf.reshape(mask,[-1,3]), axis=0)\n",
    "\n",
    "color_dict = {i: list(x) for i,x in enumerate(colors)}\n",
    "\n",
    "color_dict[1] = color_dict[0]\n",
    "color_dict[2] = color_dict[0]\n",
    "color_dict[3] = color_dict[0]\n",
    "color_dict[4] = np.array([0.0, 0.0, 1.0])\n",
    "color_dict[1] = color_dict[4]\n",
    "print(color_dict)\n",
    "\n",
    "def rgb_to_onehot(rgb_arr, color_dict):\n",
    "    num_classes = len(color_dict)\n",
    "    shape = rgb_arr.shape[:2] + (num_classes,)\n",
    "    arr = np.zeros(shape, dtype=np.int8)\n",
    "    for i, cls in enumerate(color_dict):\n",
    "        arr[:, :, i] = np.all(rgb_arr.reshape((-1, 3)) == color_dict[i], axis=1).reshape(shape[:2])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHOUT TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RlUMjm41npRV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  493.582 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "for idx,image in enumerate(tqdm(glob.glob(\"JR_dataset/test/*.bmp\"))):\n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.crop_to_bounding_box(n, CROP_SIZE[0], CROP_SIZE[1], CROP_SIZE[2], CROP_SIZE[3])\n",
    "\n",
    "    image = tf.expand_dims(image,0)\n",
    "    pred_mask.append(model(image)) # N, H, W, 3\n",
    "    \n",
    "    ex = pred_mask[idx][0] # H,W,4\n",
    "    \n",
    "    hole = np.round(tf.expand_dims(ex[:,:,1], -1)) \n",
    "    circle = np.round(tf.expand_dims(ex[:,:,0], -1))\n",
    "\n",
    "    \n",
    "    hole = hole.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "    closed_hole = cv2.dilate(hole, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_hole, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(hole, contours, label='stamp', show=False)\n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \", (np.mean(time_list) * 1000).round(3), \"ms\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hwMHOEtCqfvr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "model = tf.saved_model.load(path, tags=[trt.tag_constants.SERVING])\n",
    "graph_func = model.signatures[trt.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "frozen_func = trt.convert_to_constants.convert_variables_to_constants_v2(graph_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrWm1GYVtKvY",
    "outputId": "3ae00121-3d80-4657-aa5a-024b3b0948bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  116.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "img_loc = glob.glob(\"JR_dataset/train/*/*.bmp\")\n",
    "    \n",
    "    \n",
    "for idx,image in enumerate(tqdm(img_loc)):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.crop_to_bounding_box(n, CROP_SIZE[0], CROP_SIZE[1], CROP_SIZE[2], CROP_SIZE[3])\n",
    "\n",
    "    flipped = tf.image.flip_left_right(image)\n",
    "    \n",
    "    image = tf.expand_dims(flipped,0)\n",
    "    pred_mask.append(frozen_func(image)) # idx, 1, 1, H, W, 4\n",
    "    \n",
    "    ex = pred_mask[idx][0][0]\n",
    "    \n",
    "    hole = np.round(tf.expand_dims(ex[:,:,1], -1)) \n",
    "    circle = np.round(tf.expand_dims(ex[:,:,0], -1))\n",
    "    \n",
    "    # STAMP\n",
    "    hole = hole.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "    closed_stamp = cv2.dilate(hole, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(hole, contours, label='stamp', show=False)\n",
    "                                                                             \n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \",(np.mean(time_list) * 1000).round(3), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH4GUMO4mcAD",
    "outputId": "96931dfc-beaa-47a5-efe8-492449956ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 624, 672, 3)\n",
      "(46, 624, 672, 1)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for img in glob.glob(\"JR_dataset/train/*/*.bmp\"):\n",
    "    \n",
    "    n = cv2.imread(img)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    n = tf.image.crop_to_bounding_box(n, CROP_SIZE[0], CROP_SIZE[1], CROP_SIZE[2], CROP_SIZE[3])\n",
    "\n",
    "    flipped = tf.image.flip_left_right(n)\n",
    "\n",
    "    train_x.append(flipped)\n",
    "\n",
    "    dir = \"/\".join(img.split(\"/\")[:-1]) + \"/new_gt_mask/\"\n",
    "    file_name = img.split(\"/\")[-1].split('.')[0]\n",
    "\n",
    "    y = imread(dir+file_name+\".png\")\n",
    "\n",
    "    a = rgb_to_onehot(y, color_dict) #change to one hot\n",
    "    \n",
    "    bb = tf.expand_dims(np.argmax(a, axis=-1),-1) #combine one hot #0,1,2,3\n",
    "    bbb = tf.image.crop_to_bounding_box(bb, CROP_SIZE[0], CROP_SIZE[1], CROP_SIZE[2], CROP_SIZE[3])\n",
    "\n",
    "    flipped2 = tf.image.flip_left_right(bbb)\n",
    "\n",
    "    train_y.append(flipped2)\n",
    "\n",
    "test_x = tf.convert_to_tensor(train_x)\n",
    "test_y = tf.convert_to_tensor(train_y)\n",
    "\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3405a05f8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 29\n",
    "\n",
    "pred = np.float32(pred_mask[idx][0][0])\n",
    "ex = np.round(pred) # ex = H,W,4\n",
    "\n",
    "hole = tf.expand_dims(ex[:,:,1], -1) \n",
    "\n",
    "circle = tf.expand_dims(ex[:,:,0], -1)\n",
    "\n",
    "gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "\n",
    "display([gt_mask, hole, circle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "0QwwNKUVIyoR",
    "outputId": "1e6e11aa-bf65-47f6-dee0-a87dd665ab29"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3503252e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 hole found. Area: [16257.5, 43160.5]\n"
     ]
    }
   ],
   "source": [
    "hole = np.array(hole).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "closed_stamp = cv2.erode(hole, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(hole, contours, label=\"hole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "6hnpBdTNLnnt",
    "outputId": "3fdb3c92-53a0-4dae-85af-e56ff3e6e46d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pushed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-6c3fcddaf662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpushed_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpushed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetStructuringElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMORPH_RECT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclosing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphologyEx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpushed_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMORPH_CLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_NONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pushed' is not defined"
     ]
    }
   ],
   "source": [
    "pushed_x = np.array(pushed).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(pushed_x, contours, label='push', draw_type='contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchannel_0 = np.zeros((480,576,1)) #prediction\\nchannel_1 = np.zeros((480,576,1))\\nchannel_2 = np.zeros((480,576,1))\\n\\nchannel_0[pushed==1] = color_dict[1][0]\\nchannel_1[pushed==1] = color_dict[1][1]\\nchannel_2[pushed==1] = color_dict[1][2]\\n\\nchannel_0[circle==1] = color_dict[3][0]\\nchannel_1[circle==1] = color_dict[3][1]\\nchannel_2[circle==1] = color_dict[3][2]\\n\\nchannel_0[stamped==1] = color_dict[2][0]\\nchannel_1[stamped==1] = color_dict[2][1]\\nchannel_2[stamped==1] = color_dict[2][2]\\n\\nchannel_0[bg==1] = color_dict[0][0]\\nchannel_1[bg==1] = color_dict[0][1]\\nchannel_2[bg==1] = color_dict[0][2]\\n\\ncom = tf.concat([channel_0, channel_1, channel_2], -1)\\n'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "channel_0 = np.zeros((480,576,1)) #prediction\n",
    "channel_1 = np.zeros((480,576,1))\n",
    "channel_2 = np.zeros((480,576,1))\n",
    "\n",
    "channel_0[pushed==1] = color_dict[1][0]\n",
    "channel_1[pushed==1] = color_dict[1][1]\n",
    "channel_2[pushed==1] = color_dict[1][2]\n",
    "\n",
    "channel_0[circle==1] = color_dict[3][0]\n",
    "channel_1[circle==1] = color_dict[3][1]\n",
    "channel_2[circle==1] = color_dict[3][2]\n",
    "\n",
    "channel_0[stamped==1] = color_dict[2][0]\n",
    "channel_1[stamped==1] = color_dict[2][1]\n",
    "channel_2[stamped==1] = color_dict[2][2]\n",
    "\n",
    "channel_0[bg==1] = color_dict[0][0]\n",
    "channel_1[bg==1] = color_dict[0][1]\n",
    "channel_2[bg==1] = color_dict[0][2]\n",
    "\n",
    "com = tf.concat([channel_0, channel_1, channel_2], -1)\n",
    "\n",
    "\n",
    "display(com, idx, only_inference=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background IoU: 0.9876946 Background Accuracy: 0.995884\n",
      "Push IoU: 0.6679955 Push Accuracy: 0.41133097\n",
      "Stamp IoU: 0.54008263 Stamp Accuracy: 0.102555335\n",
      "Circle IoU: 0.98253965 Circle Accuracy: 0.98730356\n"
     ]
    }
   ],
   "source": [
    "def class_iou(gt_mask, prediction, cls = 0, metric = 'iou'):\n",
    "    \"\"\"\n",
    "    Returns IoU score if metric == 'iou', Accuracy if metric == 'acc'\n",
    "    Accuracy not recommended for evaluating segmentation task\n",
    "    \"\"\"\n",
    "    a = np.zeros(IMG_SIZE + (1,))\n",
    "    b = np.zeros(IMG_SIZE + (1,))\n",
    "    \n",
    "    a[gt_mask==cls] = 1\n",
    "    b[prediction==1] = 1\n",
    "    \n",
    "    if metric == 'iou':\n",
    "        iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "        iou.update_state(a, b)\n",
    "        return(iou.result().numpy())\n",
    "    \n",
    "    elif metric == 'acc':\n",
    "        m = tf.keras.metrics.Accuracy()\n",
    "\n",
    "        weight = np.zeros(a.shape)\n",
    "        weight[gt_mask==cls] = 1\n",
    "\n",
    "        m.update_state(a, b, sample_weight = weight)\n",
    "    \n",
    "        return(m.result().numpy())\n",
    "\n",
    "\n",
    "bg_iou = []\n",
    "push_iou = []\n",
    "stamp_iou = []\n",
    "circle_iou = []\n",
    "\n",
    "bg_acc = []\n",
    "push_acc = []\n",
    "stamp_acc = []\n",
    "circle_acc = []\n",
    "\n",
    "for idx in range(46):\n",
    "    ex = np.round(pred_mask[idx][0][0]) # ex = H,W,4\n",
    "    \n",
    "    prediction = np.zeros(IMG_SIZE + (1,))\n",
    "\n",
    "    pushed = tf.expand_dims(ex[:,:,1], -1) + tf.expand_dims(ex[:,:,2], -1)\n",
    "    circle = tf.expand_dims(ex[:,:,3], -1)\n",
    "    stamped = tf.expand_dims(ex[:,:,2], -1) # stamped = H,W,1\n",
    "    bg = tf.expand_dims(ex[:,:,0], -1)\n",
    "\n",
    "    gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "    \n",
    "    prediction[pushed==1] = 1\n",
    "    prediction[stamped==1] = 2\n",
    "    prediction[circle==1] = 3\n",
    "    prediction[bg==1] = 0\n",
    "    \n",
    "    bg_acc.append(class_iou(gt_mask, bg, metric='acc'))\n",
    "    push_acc.append(class_iou(gt_mask, pushed, cls=1, metric='acc'))\n",
    "    stamp_acc.append(class_iou(gt_mask, stamped, cls=2, metric='acc'))\n",
    "    circle_acc.append(class_iou(gt_mask, circle, cls=3, metric='acc'))\n",
    "    \n",
    "    bg_iou.append(class_iou(gt_mask,bg))\n",
    "    push_iou.append(class_iou(gt_mask,pushed,cls=1))\n",
    "    stamp_iou.append(class_iou(gt_mask,stamped,cls=2))\n",
    "    circle_iou.append(class_iou(gt_mask,circle,cls=3))\n",
    "    \n",
    "print(\"Background IoU:\", np.mean(bg_iou), \"Background Accuracy:\", np.mean(bg_acc)) #0.986\n",
    "print(\"Push IoU:\", np.mean(push_iou), \"Push Accuracy:\", np.mean(push_acc)) #0.664\n",
    "print(\"Stamp IoU:\", np.mean(stamp_iou), \"Stamp Accuracy:\", np.mean(stamp_acc)) #0.544\n",
    "print(\"Circle IoU:\", np.mean(circle_iou), \"Circle Accuracy:\", np.mean(circle_acc)) #0.981\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
