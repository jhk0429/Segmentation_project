{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZgPEymw9njoY"
   },
   "outputs": [],
   "source": [
    "#path = 'saved_model_1001_1' #epoch 60 / 20  large image x3\n",
    "#path = 'saved_model_1001_softmax_RMSprop_80_30' Not bad, little noisy.\n",
    "#path = 'saved_model_1001_softmax_RMSprop_100_30_0.0001' #less noisy but stamp not really good\n",
    "#path = 'saved_models/saved_model_1001_softmax_RMSprop_100_40_0.0005' #less noisy. stamp better.\n",
    "#path = 'saved_model_1001_softmax_Adam_100_40_0.0005' #little bit worse\n",
    "#path = 'saved_model_1005_softmax_RMSprop_100_40_0.0005_with_classweights'\n",
    "#path = 'saved_model_1005_softmax_RMSprop_100_30_0.0005_B8_with_classweights'\n",
    "#path = 'saved_model_1005_softmax_RMSprop_50_30_0.0005_B16_with_classweights_100'\n",
    "#path = 'saved_model_1005_RMSprop_100_0.0005_B1_classweights_P5_S10'\n",
    "#path = 'saved_model_1005_RMSprop_80_0.0005_BNone_classweights_P5_S30'\n",
    "#path = 'saved_model_1006_Adam_70_0.0005_BNone_classweights_P5_S50'\n",
    "#path = 'saved_model_1006_RMSprop_70_0.0005_BNone_classweights_P86_S3055'\n",
    "#path = 'saved_model_1006_RMSprop_130_0.0005_BNone_classweights_P86_S3059'\n",
    "#path = 'saved_model_1006_RMSprop_150_0.0005_BNone_classweights_P86_S3056_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_0.0005_BNone_classweights_P86_S3056_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_0.0001_BNone_classweights_P86_S3057_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_5e-05_BNone_classweights_P86_S3060_EncoderTrained'\n",
    "\n",
    "path = 'saved_model_10123_combined_RMSprop_100_5e-05_ENCFRZ_False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXRm-jLtmzga",
    "outputId": "f7f57301-6e86-4cf3-deb6-f43f81a2829f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import segmentation_models as sm\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "KLDykGNHmkjU",
    "outputId": "9da2feff-35eb-478d-d052-7c9b2807464a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n  raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\\n\""
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (480,576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r0bNqPN0sR-1"
   },
   "outputs": [],
   "source": [
    "def display(display_list, idx=None, only_inference=False, fig_size=15):\n",
    "    \"\"\"\n",
    "    \"only_inference\" = True creates sample of inferenced image PNG file.\n",
    "    \"\"\"\n",
    "    if only_inference:\n",
    "        a = np.array(display_list)\n",
    "        a = a.astype(np.float32) * 255.0\n",
    "\n",
    "        cv2.imwrite(\"EX{}.png\".format(idx), cv2.cvtColor(a, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    else:\n",
    "        plt.figure(figsize=(fig_size,fig_size))\n",
    "        title = ['Ground Truth Mask', 'Pushed', 'Stamped']\n",
    "\n",
    "        for i in range(len(display_list)):\n",
    "            plt.subplot(1, len(display_list), i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l5OoNvjhsSYQ"
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask, num=0):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[num]\n",
    "\n",
    "def show_predictions(test_mode=False, x=None,y=None, num=1):\n",
    "    if test_mode:\n",
    "        print(\"In testing Mode...\")\n",
    "        for i in range(num):\n",
    "            pred_mask = model.predict(x, batch_size=1)\n",
    "            display([x[i], y[i], create_mask(pred_mask, num=i)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_and_count(img, contours, label = '', draw_type = 'contour', show=True):\n",
    "    # img : original image\n",
    "    # contours: Contours found from opencv code\n",
    "    assert label in ['push', 'stamp'], \"label must be either 'push' or 'stamp'\"\n",
    "    assert draw_type in ['bbox', 'contour'], \"draw type must be either 'bbox' or 'contour'\"\n",
    "    \n",
    "    if label=='push': val = 220\n",
    "    if label=='stamp': val = 150\n",
    "        \n",
    "    count = 0\n",
    "    area = []\n",
    "    width_height = []\n",
    "    \n",
    "    for idx, cnt in enumerate(contours):\n",
    "        a = cv2.contourArea(cnt)\n",
    "        if a < val:\n",
    "            continue\n",
    "        \n",
    "        area.append(a)\n",
    "        count += 1\n",
    "        \n",
    "        if draw_type == 'bbox':\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(125,125,0),2)\n",
    "            width_height.append([w,h])\n",
    "            print(\"{} #{} has width of {} and height of {}\".format(label, idx, w, h))\n",
    "            \n",
    "        elif draw_type == 'contour':\n",
    "            cv2.drawContours(img, [cnt], 0, (125, 125, 0), 2) \n",
    "            \n",
    "    if show:        \n",
    "        display([img], fig_size=8)\n",
    "        print(\"{} {} found. Area: {}\".format(count,label,area))\n",
    "\n",
    "        \n",
    "    return img, area, width_height, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twqjJGlpgxFv",
    "outputId": "c47d45d0-441e-4991-97b0-01f0e2b1108e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0, 0.0, 0.0], 1: [0.9607843, 0.5764706, 0.19215687], 2: [0.98039216, 0.19607843, 0.3254902], 3: [0.98039216, 0.98039216, 0.21568628], 4: array([0, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "mask = imread('JR_dataset/train/silver_ng/new_gt_mask/높음2__분리막 눌림_은색.png') #2048 x 2448\n",
    "\n",
    "colors = np.unique(tf.reshape(mask,[-1,3]), axis=0)\n",
    "\n",
    "color_dict = {i: list(x) for i,x in enumerate(colors)}\n",
    "\n",
    "color_dict[1] = color_dict[2]\n",
    "color_dict[2] = color_dict[3]\n",
    "color_dict[3] = color_dict[4]\n",
    "color_dict[4] = np.array([0,0,1])\n",
    "\n",
    "print(color_dict)\n",
    "\n",
    "def rgb_to_onehot(rgb_arr, color_dict):\n",
    "    num_classes = len(color_dict)\n",
    "    shape = rgb_arr.shape[:2] + (num_classes,)\n",
    "    arr = np.zeros(shape, dtype=np.int8)\n",
    "    for i, cls in enumerate(color_dict):\n",
    "        arr[:, :, i] = np.all(rgb_arr.reshape((-1, 3)) == color_dict[i], axis=1).reshape(shape[:2])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHOUT TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RlUMjm41npRV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:04<00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  96.475 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "for idx,image in enumerate(tqdm(glob.glob(\"images/test/*.bmp\"))):\n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.resize(n, IMG_SIZE) \n",
    "    \n",
    "    image = tf.expand_dims(image,0)\n",
    "    pred_mask.append(model(image)) # N, H, W, 3\n",
    "    \n",
    "    ex = pred_mask[idx][0] # H,W,4\n",
    "    \n",
    "    pushed = np.round(tf.expand_dims(ex[:,:,1], -1)) + np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    circle = np.round(tf.expand_dims(ex[:,:,3], -1))\n",
    "    stamped = np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    \n",
    "    stamped_x = stamped.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    closed_stamp = cv2.dilate(stamped_x, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(stamped_x, contours, label='stamp', show=False)\n",
    "    \n",
    "    pushed_x = pushed.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "    closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    push_img, push_area, wh, pushed_count = draw_and_count(pushed_x, contours, label='push', show=False)\n",
    "    \n",
    "    #print(\"Sample #{} has {} stamps and {} pushes. Stamp areas: {}, Push areas: {}\".format(idx, stamp_count, pushed_count, \n",
    "    #                                                                                 stamp_area, push_area))\n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \", (np.mean(time_list) * 1000).round(3), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hwMHOEtCqfvr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "model = tf.saved_model.load(path, tags=[trt.tag_constants.SERVING])\n",
    "graph_func = model.signatures[trt.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "frozen_func = trt.convert_to_constants.convert_variables_to_constants_v2(graph_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrWm1GYVtKvY",
    "outputId": "3ae00121-3d80-4657-aa5a-024b3b0948bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  52.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "img_loc = glob.glob(\"JR_dataset/test/*.bmp\")\n",
    "    \n",
    "    \n",
    "for idx,image in enumerate(tqdm(img_loc)):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.resize(n, IMG_SIZE) #960,1152\n",
    "    \n",
    "    #flipped = tf.image.flip_left_right(image)\n",
    "    \n",
    "    image = tf.expand_dims(image,0)\n",
    "    pred_mask.append(frozen_func(image)) # idx, 1, 1, H, W, 4\n",
    "    \n",
    "    ex = pred_mask[idx][0][0]\n",
    "    \n",
    "    pushed = np.round(tf.expand_dims(ex[:,:,1], -1)) + np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    circle = np.round(tf.expand_dims(ex[:,:,3], -1))\n",
    "    stamped = np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    hole = np.round(tf.expand_dims(ex[:,:,4], -1))\n",
    "    \n",
    "    # STAMP\n",
    "    stamped_x = stamped.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    closed_stamp = cv2.dilate(stamped_x, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(stamped_x, contours, label='stamp', show=False)\n",
    "    \n",
    "    # PUSH\n",
    "    pushed_x = pushed.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "    closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    push_img, push_area, wh, pushed_count = draw_and_count(pushed_x, contours, label='push', show=False)\n",
    "\n",
    "\n",
    "    #print(\"Sample #{} has {} stamps and {} pushes. Stamp areas: {}, Push areas: {}\".format(idx, stamp_count, pushed_count, \n",
    "    #                                                                                  stamp_area, push_area))\n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \",(np.mean(time_list) * 1000).round(3), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH4GUMO4mcAD",
    "outputId": "96931dfc-beaa-47a5-efe8-492449956ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 480, 576, 3)\n",
      "(4, 480, 576, 1)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for img in glob.glob(\"JR_dataset/test/*.bmp\"):\n",
    "    \n",
    "    n = cv2.imread(img)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    n = tf.image.resize(n, IMG_SIZE) #960,1152\n",
    "\n",
    "    #flipped = tf.image.flip_left_right(n)\n",
    "\n",
    "    train_x.append(n)\n",
    "\n",
    "    dir = \"/\".join(img.split(\"/\")[:-1]) + \"/new_gt_mask/\"\n",
    "    file_name = img.split(\"/\")[-1].split('.')[0]\n",
    "\n",
    "    y = imread(dir+file_name+\".png\")\n",
    "\n",
    "    a = rgb_to_onehot(y, color_dict) #change to one hot\n",
    "    \n",
    "    bb = tf.expand_dims(np.argmax(a, axis=-1),-1) #combine one hot #0,1,2,3\n",
    "    bbb = tf.image.resize(bb, IMG_SIZE) #960,1152\n",
    "    \n",
    "    #flipped2 = tf.image.flip_left_right(bbb)\n",
    "\n",
    "    train_y.append(bbb)\n",
    "\n",
    "test_x = tf.convert_to_tensor(train_x)\n",
    "test_y = tf.convert_to_tensor(train_y)\n",
    "\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZoMYAYb4Sv7"
   },
   "source": [
    "Ground truth numbers:\n",
    "1.   black_ng:\n",
    "1, 2/1, 3, 4, 4/2, 4/2, 3/1, 1, 1, 4/1\n",
    "3/3, 2, 4/1, 3/1\n",
    "2.   silver_ng:\n",
    "4, 4/1, 4/2, 3/1, 1, 1/1, 4/1,\n",
    "3/2, 2, 4, 2/1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('test_img_array', test_0 = np.float32(pred_mask[0][0][0]), test_1 = np.float32(pred_mask[1][0][0]), \n",
    "                   test_2 = np.float32(pred_mask[2][0][0]), test_3 = np.float32(pred_mask[3][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f322441ccf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3\n",
    "\n",
    "pred = np.float32(pred_mask[idx][0][0])\n",
    "\n",
    "ex = np.round(pred) # ex = H,W,4\n",
    "\n",
    "pushed = tf.expand_dims(ex[:,:,1], -1) + tf.expand_dims(ex[:,:,2], -1)\n",
    "circle = tf.expand_dims(ex[:,:,3], -1)\n",
    "stamped = tf.expand_dims(ex[:,:,2], -1) # stamped = H,W,1\n",
    "bg = tf.expand_dims(ex[:,:,0], -1)\n",
    "hole = tf.expand_dims(ex[:,:,4], -1)\n",
    "\n",
    "\n",
    "#bg = 0, pushed = 1, stamped = 2, circle = 3\n",
    "\n",
    "gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "#print((gt_mask==1).sum())\n",
    "\n",
    "display([gt_mask, pushed, hole])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 576, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nchannel_0 = np.zeros((480,576,1)) #prediction\\nchannel_1 = np.zeros((480,576,1))\\nchannel_2 = np.zeros((480,576,1))\\n\\nchannel_0[pushed==1] = color_dict[1][0]\\nchannel_1[pushed==1] = color_dict[1][1]\\nchannel_2[pushed==1] = color_dict[1][2]\\n\\nchannel_0[circle==1] = color_dict[3][0]\\nchannel_1[circle==1] = color_dict[3][1]\\nchannel_2[circle==1] = color_dict[3][2]\\n\\nchannel_0[stamped==1] = color_dict[2][0]\\nchannel_1[stamped==1] = color_dict[2][1]\\nchannel_2[stamped==1] = color_dict[2][2]\\n\\nchannel_0[bg==1] = color_dict[0][0]\\nchannel_1[bg==1] = color_dict[0][1]\\nchannel_2[bg==1] = color_dict[0][2]\\n\\ncom = tf.concat([channel_0, channel_1, channel_2], -1)\\n\\ndisplay(com, idx, only_inference=True)\\n'"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = np.load('test_img_array.npz')\n",
    "\n",
    "print(loaded['test_0'].shape)\n",
    "\n",
    "\"\"\"\n",
    "channel_0 = np.zeros((480,576,1)) #prediction\n",
    "channel_1 = np.zeros((480,576,1))\n",
    "channel_2 = np.zeros((480,576,1))\n",
    "\n",
    "channel_0[pushed==1] = color_dict[1][0]\n",
    "channel_1[pushed==1] = color_dict[1][1]\n",
    "channel_2[pushed==1] = color_dict[1][2]\n",
    "\n",
    "channel_0[circle==1] = color_dict[3][0]\n",
    "channel_1[circle==1] = color_dict[3][1]\n",
    "channel_2[circle==1] = color_dict[3][2]\n",
    "\n",
    "channel_0[stamped==1] = color_dict[2][0]\n",
    "channel_1[stamped==1] = color_dict[2][1]\n",
    "channel_2[stamped==1] = color_dict[2][2]\n",
    "\n",
    "channel_0[bg==1] = color_dict[0][0]\n",
    "channel_1[bg==1] = color_dict[0][1]\n",
    "channel_2[bg==1] = color_dict[0][2]\n",
    "\n",
    "com = tf.concat([channel_0, channel_1, channel_2], -1)\n",
    "\n",
    "display(com, idx, only_inference=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "0QwwNKUVIyoR",
    "outputId": "1e6e11aa-bf65-47f6-dee0-a87dd665ab29"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff8e00ed320>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 stamp found. Area: [1231.0]\n"
     ]
    }
   ],
   "source": [
    "stamped_x = np.array(stamped).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "closed_stamp = cv2.dilate(stamped_x, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(stamped_x, contours, label=\"stamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "6hnpBdTNLnnt",
    "outputId": "3fdb3c92-53a0-4dae-85af-e56ff3e6e46d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff8e00e2320>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 push found. Area: [7910.0, 4515.0, 1256.5, 428.0]\n"
     ]
    }
   ],
   "source": [
    "pushed_x = np.array(pushed).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(pushed_x, contours, label='push', draw_type='contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchannel_0 = np.zeros((480,576,1)) #prediction\\nchannel_1 = np.zeros((480,576,1))\\nchannel_2 = np.zeros((480,576,1))\\n\\nchannel_0[pushed==1] = color_dict[1][0]\\nchannel_1[pushed==1] = color_dict[1][1]\\nchannel_2[pushed==1] = color_dict[1][2]\\n\\nchannel_0[circle==1] = color_dict[3][0]\\nchannel_1[circle==1] = color_dict[3][1]\\nchannel_2[circle==1] = color_dict[3][2]\\n\\nchannel_0[stamped==1] = color_dict[2][0]\\nchannel_1[stamped==1] = color_dict[2][1]\\nchannel_2[stamped==1] = color_dict[2][2]\\n\\nchannel_0[bg==1] = color_dict[0][0]\\nchannel_1[bg==1] = color_dict[0][1]\\nchannel_2[bg==1] = color_dict[0][2]\\n\\ncom = tf.concat([channel_0, channel_1, channel_2], -1)\\n'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "channel_0 = np.zeros((480,576,1)) #prediction\n",
    "channel_1 = np.zeros((480,576,1))\n",
    "channel_2 = np.zeros((480,576,1))\n",
    "\n",
    "channel_0[pushed==1] = color_dict[1][0]\n",
    "channel_1[pushed==1] = color_dict[1][1]\n",
    "channel_2[pushed==1] = color_dict[1][2]\n",
    "\n",
    "channel_0[circle==1] = color_dict[3][0]\n",
    "channel_1[circle==1] = color_dict[3][1]\n",
    "channel_2[circle==1] = color_dict[3][2]\n",
    "\n",
    "channel_0[stamped==1] = color_dict[2][0]\n",
    "channel_1[stamped==1] = color_dict[2][1]\n",
    "channel_2[stamped==1] = color_dict[2][2]\n",
    "\n",
    "channel_0[bg==1] = color_dict[0][0]\n",
    "channel_1[bg==1] = color_dict[0][1]\n",
    "channel_2[bg==1] = color_dict[0][2]\n",
    "\n",
    "com = tf.concat([channel_0, channel_1, channel_2], -1)\n",
    "\n",
    "\n",
    "display(com, idx, only_inference=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background IoU: 0.97386056 Background Accuracy: 0.98271155\n",
      "Push IoU: 0.8832178 Push Accuracy: 0.81973827\n",
      "Stamp IoU: 0.57585377 Stamp Accuracy: 0.22148688\n",
      "Circle IoU: 0.9342415 Circle Accuracy: 0.9592601\n"
     ]
    }
   ],
   "source": [
    "def class_iou(gt_mask, prediction, cls = 0, metric = 'iou'):\n",
    "    \"\"\"\n",
    "    Returns IoU score if metric == 'iou', Accuracy if metric == 'acc'\n",
    "    Accuracy not recommended for evaluating segmentation task\n",
    "    \"\"\"\n",
    "    a = np.zeros(IMG_SIZE + (1,))\n",
    "    b = np.zeros(IMG_SIZE + (1,))\n",
    "    \n",
    "    a[gt_mask==cls] = 1\n",
    "    b[prediction==1] = 1\n",
    "    \n",
    "    if metric == 'iou':\n",
    "        iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "        iou.update_state(a, b)\n",
    "        return(iou.result().numpy())\n",
    "    \n",
    "    elif metric == 'acc':\n",
    "        m = tf.keras.metrics.Accuracy()\n",
    "\n",
    "        weight = np.zeros(a.shape)\n",
    "        weight[gt_mask==cls] = 1\n",
    "\n",
    "        m.update_state(a, b, sample_weight = weight)\n",
    "    \n",
    "        return(m.result().numpy())\n",
    "\n",
    "\n",
    "bg_iou = []\n",
    "push_iou = []\n",
    "stamp_iou = []\n",
    "circle_iou = []\n",
    "\n",
    "bg_acc = []\n",
    "push_acc = []\n",
    "stamp_acc = []\n",
    "circle_acc = []\n",
    "\n",
    "for idx in range(4):\n",
    "    ex = np.round(pred_mask[idx][0][0]) # ex = H,W,4\n",
    "    \n",
    "    prediction = np.zeros(IMG_SIZE + (1,))\n",
    "\n",
    "    pushed = tf.expand_dims(ex[:,:,1], -1) + tf.expand_dims(ex[:,:,2], -1)\n",
    "    circle = tf.expand_dims(ex[:,:,3], -1)\n",
    "    stamped = tf.expand_dims(ex[:,:,2], -1) # stamped = H,W,1\n",
    "    bg = tf.expand_dims(ex[:,:,0], -1)\n",
    "\n",
    "    gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "    \n",
    "    prediction[pushed==1] = 1\n",
    "    prediction[stamped==1] = 2\n",
    "    prediction[circle==1] = 3\n",
    "    prediction[bg==1] = 0\n",
    "    \n",
    "    bg_acc.append(class_iou(gt_mask, bg, metric='acc'))\n",
    "    push_acc.append(class_iou(gt_mask, pushed, cls=1, metric='acc'))\n",
    "    stamp_acc.append(class_iou(gt_mask, stamped, cls=2, metric='acc'))\n",
    "    circle_acc.append(class_iou(gt_mask, circle, cls=3, metric='acc'))\n",
    "    \n",
    "    bg_iou.append(class_iou(gt_mask,bg))\n",
    "    push_iou.append(class_iou(gt_mask,pushed,cls=1))\n",
    "    stamp_iou.append(class_iou(gt_mask,stamped,cls=2))\n",
    "    circle_iou.append(class_iou(gt_mask,circle,cls=3))\n",
    "    \n",
    "print(\"Background IoU:\", np.mean(bg_iou), \"Background Accuracy:\", np.mean(bg_acc)) #0.986\n",
    "print(\"Push IoU:\", np.mean(push_iou), \"Push Accuracy:\", np.mean(push_acc)) #0.664\n",
    "print(\"Stamp IoU:\", np.mean(stamp_iou), \"Stamp Accuracy:\", np.mean(stamp_acc)) #0.544\n",
    "print(\"Circle IoU:\", np.mean(circle_iou), \"Circle Accuracy:\", np.mean(circle_acc)) #0.981\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
