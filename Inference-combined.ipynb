{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZgPEymw9njoY"
   },
   "outputs": [],
   "source": [
    "#path = 'saved_model_1001_1' #epoch 60 / 20  large image x3\n",
    "#path = 'saved_model_1001_softmax_RMSprop_80_30' Not bad, little noisy.\n",
    "#path = 'saved_model_1001_softmax_RMSprop_100_30_0.0001' #less noisy but stamp not really good\n",
    "#path = 'saved_models/saved_model_1001_softmax_RMSprop_100_40_0.0005' #less noisy. stamp better.\n",
    "#path = 'saved_model_1001_softmax_Adam_100_40_0.0005' #little bit worse\n",
    "#path = 'saved_model_1005_softmax_RMSprop_100_40_0.0005_with_classweights'\n",
    "#path = 'saved_model_1005_softmax_RMSprop_100_30_0.0005_B8_with_classweights'\n",
    "#path = 'saved_model_1005_softmax_RMSprop_50_30_0.0005_B16_with_classweights_100'\n",
    "#path = 'saved_model_1005_RMSprop_100_0.0005_B1_classweights_P5_S10'\n",
    "#path = 'saved_model_1005_RMSprop_80_0.0005_BNone_classweights_P5_S30'\n",
    "#path = 'saved_model_1006_Adam_70_0.0005_BNone_classweights_P5_S50'\n",
    "#path = 'saved_model_1006_RMSprop_70_0.0005_BNone_classweights_P86_S3055'\n",
    "#path = 'saved_model_1006_RMSprop_130_0.0005_BNone_classweights_P86_S3059'\n",
    "#path = 'saved_model_1006_RMSprop_150_0.0005_BNone_classweights_P86_S3056_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_0.0005_BNone_classweights_P86_S3056_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_0.0001_BNone_classweights_P86_S3057_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_5e-05_BNone_classweights_P86_S3060_EncoderTrained'\n",
    "\n",
    "#path = 'saved_model_10123_combined_RMSprop_100_5e-05_ENCFRZ_False'\n",
    "#path = 'saved_model_1014_combined_RMSprop_100_0.0001_ENCFRZ_False'\n",
    "path = 'saved_model_1014_combined_RMSprop_100_0.0001_ENCFRZ_False_onechannel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXRm-jLtmzga",
    "outputId": "f7f57301-6e86-4cf3-deb6-f43f81a2829f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import segmentation_models as sm\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "KLDykGNHmkjU",
    "outputId": "9da2feff-35eb-478d-d052-7c9b2807464a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n  raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (480,576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r0bNqPN0sR-1"
   },
   "outputs": [],
   "source": [
    "def display(display_list, idx=None, only_inference=False, fig_size=15):\n",
    "    \"\"\"\n",
    "    \"only_inference\" = True creates sample of inferenced image PNG file.\n",
    "    \"\"\"\n",
    "    if only_inference:\n",
    "        a = np.array(display_list)\n",
    "        a = a.astype(np.float32) * 255.0\n",
    "\n",
    "        cv2.imwrite(\"EX{}.png\".format(idx), cv2.cvtColor(a, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    else:\n",
    "        plt.figure(figsize=(fig_size,fig_size))\n",
    "        title = ['Ground Truth Mask', 'Pushed', 'Stamped']\n",
    "\n",
    "        for i in range(len(display_list)):\n",
    "            plt.subplot(1, len(display_list), i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l5OoNvjhsSYQ"
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask, num=0):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[num]\n",
    "\n",
    "def show_predictions(test_mode=False, x=None,y=None, num=1):\n",
    "    if test_mode:\n",
    "        print(\"In testing Mode...\")\n",
    "        for i in range(num):\n",
    "            pred_mask = model.predict(x, batch_size=1)\n",
    "            display([x[i], y[i], create_mask(pred_mask, num=i)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_and_count(img, contours, label = '', draw_type = 'contour', show=True):\n",
    "    # img : original image\n",
    "    # contours: Contours found from opencv code\n",
    "    assert label in ['push', 'stamp', 'hole'], \"label must be either 'push' or 'stamp'\"\n",
    "    assert draw_type in ['bbox', 'contour'], \"draw type must be either 'bbox' or 'contour'\"\n",
    "    \n",
    "    if label=='push': val = 220\n",
    "    if label=='stamp': val = 150\n",
    "    if label=='hole': val = 300\n",
    "        \n",
    "        \n",
    "    count = 0\n",
    "    area = []\n",
    "    width_height = []\n",
    "    \n",
    "    for idx, cnt in enumerate(contours):\n",
    "        a = cv2.contourArea(cnt)\n",
    "        if a < val:\n",
    "            continue\n",
    "        \n",
    "        area.append(a)\n",
    "        count += 1\n",
    "        \n",
    "        if draw_type == 'bbox':\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(125,125,0),2)\n",
    "            width_height.append([w,h])\n",
    "            print(\"{} #{} has width of {} and height of {}\".format(label, idx, w, h))\n",
    "            \n",
    "        elif draw_type == 'contour':\n",
    "            cv2.drawContours(img, [cnt], 0, (125, 125, 0), 2) \n",
    "            \n",
    "    if show:        \n",
    "        display([img], fig_size=8)\n",
    "        print(\"{} {} found. Area: {}\".format(count,label,area))\n",
    "\n",
    "        \n",
    "    return img, area, width_height, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twqjJGlpgxFv",
    "outputId": "c47d45d0-441e-4991-97b0-01f0e2b1108e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0, 0.0, 0.0], 1: [0.9607843, 0.5764706, 0.19215687], 2: [0.98039216, 0.19607843, 0.3254902], 3: [0.98039216, 0.98039216, 0.21568628], 4: array([0, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "mask = imread('JR_dataset/train/silver_ng/new_gt_mask/높음2__분리막 눌림_은색.png') #2048 x 2448\n",
    "\n",
    "colors = np.unique(tf.reshape(mask,[-1,3]), axis=0)\n",
    "\n",
    "color_dict = {i: list(x) for i,x in enumerate(colors)}\n",
    "\n",
    "color_dict[1] = color_dict[2]\n",
    "color_dict[2] = color_dict[3]\n",
    "color_dict[3] = color_dict[4]\n",
    "color_dict[4] = np.array([0,0,1])\n",
    "\n",
    "print(color_dict)\n",
    "\n",
    "def rgb_to_onehot(rgb_arr, color_dict):\n",
    "    num_classes = len(color_dict)\n",
    "    shape = rgb_arr.shape[:2] + (num_classes,)\n",
    "    arr = np.zeros(shape, dtype=np.int8)\n",
    "    for i, cls in enumerate(color_dict):\n",
    "        arr[:, :, i] = np.all(rgb_arr.reshape((-1, 3)) == color_dict[i], axis=1).reshape(shape[:2])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHOUT TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RlUMjm41npRV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:04<00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  96.475 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "for idx,image in enumerate(tqdm(glob.glob(\"images/test/*.bmp\"))):\n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.resize(n, IMG_SIZE) \n",
    "    \n",
    "    image = tf.expand_dims(image,0)\n",
    "    pred_mask.append(model(image)) # N, H, W, 3\n",
    "    \n",
    "    ex = pred_mask[idx][0] # H,W,4\n",
    "    \n",
    "    pushed = np.round(tf.expand_dims(ex[:,:,1], -1)) + np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    circle = np.round(tf.expand_dims(ex[:,:,3], -1))\n",
    "    stamped = np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    \n",
    "    stamped_x = stamped.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    closed_stamp = cv2.dilate(stamped_x, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(stamped_x, contours, label='stamp', show=False)\n",
    "    \n",
    "    pushed_x = pushed.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "    closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    push_img, push_area, wh, pushed_count = draw_and_count(pushed_x, contours, label='push', show=False)\n",
    "    \n",
    "    #print(\"Sample #{} has {} stamps and {} pushes. Stamp areas: {}, Push areas: {}\".format(idx, stamp_count, pushed_count, \n",
    "    #                                                                                 stamp_area, push_area))\n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \", (np.mean(time_list) * 1000).round(3), \"ms\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hwMHOEtCqfvr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "model = tf.saved_model.load(path, tags=[trt.tag_constants.SERVING])\n",
    "graph_func = model.signatures[trt.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "frozen_func = trt.convert_to_constants.convert_variables_to_constants_v2(graph_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrWm1GYVtKvY",
    "outputId": "3ae00121-3d80-4657-aa5a-024b3b0948bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:02<00:00, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  46.69 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "img_loc = glob.glob(\"JR_dataset/train/*/*.bmp\")\n",
    "    \n",
    "    \n",
    "for idx,image in enumerate(tqdm(img_loc)):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.resize(n, IMG_SIZE) #960,1152\n",
    "    \n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    \n",
    "    image = tf.image.flip_left_right(image)\n",
    "    \n",
    "    image = tf.expand_dims(image,0)\n",
    "    pred_mask.append(frozen_func(image)) # idx, 1, 1, H, W, 4\n",
    "    \n",
    "    ex = pred_mask[idx][0][0]\n",
    "    \n",
    "    pushed = np.round(tf.expand_dims(ex[:,:,1], -1)) + np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    circle = np.round(tf.expand_dims(ex[:,:,3], -1))\n",
    "    stamped = np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    hole = np.round(tf.expand_dims(ex[:,:,4], -1))\n",
    "    \n",
    "    # STAMP\n",
    "    stamped_x = stamped.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    closed_stamp = cv2.dilate(stamped_x, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(stamped_x, contours, label='stamp', show=False)\n",
    "    \n",
    "    # PUSH\n",
    "    pushed_x = pushed.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "    closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    push_img, push_area, wh, pushed_count = draw_and_count(pushed_x, contours, label='push', show=False)\n",
    "\n",
    "\n",
    "    #print(\"Sample #{} has {} stamps and {} pushes. Stamp areas: {}, Push areas: {}\".format(idx, stamp_count, pushed_count, \n",
    "    #                                                                                  stamp_area, push_area))\n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \",(np.mean(time_list) * 1000).round(3), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH4GUMO4mcAD",
    "outputId": "96931dfc-beaa-47a5-efe8-492449956ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 480, 576, 1)\n",
      "(46, 480, 576, 1)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for img in glob.glob(\"JR_dataset/train/*/*.bmp\"):\n",
    "    \n",
    "    n = cv2.imread(img)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    n = tf.image.resize(n, IMG_SIZE) #960,1152\n",
    "    \n",
    "    n = tf.image.rgb_to_grayscale(n)\n",
    "\n",
    "    n = tf.image.flip_left_right(n)\n",
    "\n",
    "    train_x.append(n)\n",
    "\n",
    "    dir = \"/\".join(img.split(\"/\")[:-1]) + \"/new_gt_mask/\"\n",
    "    file_name = img.split(\"/\")[-1].split('.')[0]\n",
    "\n",
    "    y = imread(dir+file_name+\".png\")\n",
    "\n",
    "    a = rgb_to_onehot(y, color_dict) #change to one hot\n",
    "    \n",
    "    bb = tf.expand_dims(np.argmax(a, axis=-1),-1) #combine one hot #0,1,2,3\n",
    "    bbb = tf.image.resize(bb, IMG_SIZE) #960,1152\n",
    "    \n",
    "    bbb = tf.image.flip_left_right(bbb)\n",
    "\n",
    "    train_y.append(bbb)\n",
    "\n",
    "test_x = tf.convert_to_tensor(train_x)\n",
    "test_y = tf.convert_to_tensor(train_y)\n",
    "\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZoMYAYb4Sv7"
   },
   "source": [
    "Ground truth numbers:\n",
    "1.   black_ng:\n",
    "1, 2/1, 3, 4, 4/2, 4/2, 3/1, 1, 1, 4/1\n",
    "3/3, 2, 4/1, 3/1\n",
    "2.   silver_ng:\n",
    "4, 4/1, 4/2, 3/1, 1, 1/1, 4/1,\n",
    "3/2, 2, 4, 2/1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "np.savez_compressed('test_img_array', test_0 = np.float32(pred_mask[0][0][0]), test_1 = np.float32(pred_mask[1][0][0]), \n",
    "                   test_2 = np.float32(pred_mask[2][0][0]), test_3 = np.float32(pred_mask[3][0][0]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e1fe89438>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "\n",
    "pred = np.float32(pred_mask[idx][0][0])\n",
    "\n",
    "ex = np.round(pred) # ex = H,W,5\n",
    "\n",
    "pushed = tf.expand_dims(ex[:,:,1], -1) + tf.expand_dims(ex[:,:,2], -1)\n",
    "circle = tf.expand_dims(ex[:,:,3], -1)\n",
    "stamped = tf.expand_dims(ex[:,:,2], -1) # stamped = H,W,1\n",
    "bg = tf.expand_dims(ex[:,:,0], -1)\n",
    "hole = tf.expand_dims(ex[:,:,4], -1)\n",
    "\n",
    "\n",
    "#bg = 0, pushed = 1, stamped = 2, circle = 3\n",
    "\n",
    "gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "#print((gt_mask==1).sum())\n",
    "\n",
    "display([gt_mask, pushed, hole])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "0QwwNKUVIyoR",
    "outputId": "1e6e11aa-bf65-47f6-dee0-a87dd665ab29"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cac360fd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 stamp found. Area: []\n"
     ]
    }
   ],
   "source": [
    "stamped_x = np.array(stamped).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "closed_stamp = cv2.dilate(stamped_x, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(stamped_x, contours, label=\"stamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "6hnpBdTNLnnt",
    "outputId": "3fdb3c92-53a0-4dae-85af-e56ff3e6e46d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cac4fe0f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 push found. Area: [1025.5, 1126.5]\n"
     ]
    }
   ],
   "source": [
    "pushed_x = np.array(pushed).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(pushed_x, contours, label='push', draw_type='contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cac4fe5c0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 hole found. Area: [2059.0, 557.0]\n"
     ]
    }
   ],
   "source": [
    "hole = np.array(hole).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "closing = cv2.erode(hole, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(hole, contours, label='hole', draw_type='contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchannel_0 = np.zeros((480,576,1)) #prediction\\nchannel_1 = np.zeros((480,576,1))\\nchannel_2 = np.zeros((480,576,1))\\n\\nchannel_0[pushed==1] = color_dict[1][0]\\nchannel_1[pushed==1] = color_dict[1][1]\\nchannel_2[pushed==1] = color_dict[1][2]\\n\\nchannel_0[circle==1] = color_dict[3][0]\\nchannel_1[circle==1] = color_dict[3][1]\\nchannel_2[circle==1] = color_dict[3][2]\\n\\nchannel_0[stamped==1] = color_dict[2][0]\\nchannel_1[stamped==1] = color_dict[2][1]\\nchannel_2[stamped==1] = color_dict[2][2]\\n\\nchannel_0[bg==1] = color_dict[0][0]\\nchannel_1[bg==1] = color_dict[0][1]\\nchannel_2[bg==1] = color_dict[0][2]\\n\\ncom = tf.concat([channel_0, channel_1, channel_2], -1)\\n\\n\\ndisplay(com, idx, only_inference=True)\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "channel_0 = np.zeros((480,576,1)) #prediction\n",
    "channel_1 = np.zeros((480,576,1))\n",
    "channel_2 = np.zeros((480,576,1))\n",
    "\n",
    "channel_0[pushed==1] = color_dict[1][0]\n",
    "channel_1[pushed==1] = color_dict[1][1]\n",
    "channel_2[pushed==1] = color_dict[1][2]\n",
    "\n",
    "channel_0[circle==1] = color_dict[3][0]\n",
    "channel_1[circle==1] = color_dict[3][1]\n",
    "channel_2[circle==1] = color_dict[3][2]\n",
    "\n",
    "channel_0[stamped==1] = color_dict[2][0]\n",
    "channel_1[stamped==1] = color_dict[2][1]\n",
    "channel_2[stamped==1] = color_dict[2][2]\n",
    "\n",
    "channel_0[bg==1] = color_dict[0][0]\n",
    "channel_1[bg==1] = color_dict[0][1]\n",
    "channel_2[bg==1] = color_dict[0][2]\n",
    "\n",
    "com = tf.concat([channel_0, channel_1, channel_2], -1)\n",
    "\n",
    "\n",
    "display(com, idx, only_inference=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background IoU: 0.97386056 Background Accuracy: 0.98271155\n",
      "Push IoU: 0.8832178 Push Accuracy: 0.81973827\n",
      "Stamp IoU: 0.57585377 Stamp Accuracy: 0.22148688\n",
      "Circle IoU: 0.9342415 Circle Accuracy: 0.9592601\n"
     ]
    }
   ],
   "source": [
    "def class_iou(gt_mask, prediction, cls = 0, metric = 'iou'):\n",
    "    \"\"\"\n",
    "    Returns IoU score if metric == 'iou', Accuracy if metric == 'acc'\n",
    "    Accuracy not recommended for evaluating segmentation task\n",
    "    \"\"\"\n",
    "    a = np.zeros(IMG_SIZE + (1,))\n",
    "    b = np.zeros(IMG_SIZE + (1,))\n",
    "    \n",
    "    a[gt_mask==cls] = 1\n",
    "    b[prediction==1] = 1\n",
    "    \n",
    "    if metric == 'iou':\n",
    "        iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "        iou.update_state(a, b)\n",
    "        return(iou.result().numpy())\n",
    "    \n",
    "    elif metric == 'acc':\n",
    "        m = tf.keras.metrics.Accuracy()\n",
    "\n",
    "        weight = np.zeros(a.shape)\n",
    "        weight[gt_mask==cls] = 1\n",
    "\n",
    "        m.update_state(a, b, sample_weight = weight)\n",
    "    \n",
    "        return(m.result().numpy())\n",
    "\n",
    "\n",
    "bg_iou = []\n",
    "push_iou = []\n",
    "stamp_iou = []\n",
    "circle_iou = []\n",
    "\n",
    "bg_acc = []\n",
    "push_acc = []\n",
    "stamp_acc = []\n",
    "circle_acc = []\n",
    "\n",
    "for idx in range(4):\n",
    "    ex = np.round(pred_mask[idx][0][0]) # ex = H,W,4\n",
    "    \n",
    "    prediction = np.zeros(IMG_SIZE + (1,))\n",
    "\n",
    "    pushed = tf.expand_dims(ex[:,:,1], -1) + tf.expand_dims(ex[:,:,2], -1)\n",
    "    circle = tf.expand_dims(ex[:,:,3], -1)\n",
    "    stamped = tf.expand_dims(ex[:,:,2], -1) # stamped = H,W,1\n",
    "    bg = tf.expand_dims(ex[:,:,0], -1)\n",
    "\n",
    "    gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "    \n",
    "    prediction[pushed==1] = 1\n",
    "    prediction[stamped==1] = 2\n",
    "    prediction[circle==1] = 3\n",
    "    prediction[bg==1] = 0\n",
    "    \n",
    "    bg_acc.append(class_iou(gt_mask, bg, metric='acc'))\n",
    "    push_acc.append(class_iou(gt_mask, pushed, cls=1, metric='acc'))\n",
    "    stamp_acc.append(class_iou(gt_mask, stamped, cls=2, metric='acc'))\n",
    "    circle_acc.append(class_iou(gt_mask, circle, cls=3, metric='acc'))\n",
    "    \n",
    "    bg_iou.append(class_iou(gt_mask,bg))\n",
    "    push_iou.append(class_iou(gt_mask,pushed,cls=1))\n",
    "    stamp_iou.append(class_iou(gt_mask,stamped,cls=2))\n",
    "    circle_iou.append(class_iou(gt_mask,circle,cls=3))\n",
    "    \n",
    "print(\"Background IoU:\", np.mean(bg_iou), \"Background Accuracy:\", np.mean(bg_acc)) #0.986\n",
    "print(\"Push IoU:\", np.mean(push_iou), \"Push Accuracy:\", np.mean(push_acc)) #0.664\n",
    "print(\"Stamp IoU:\", np.mean(stamp_iou), \"Stamp Accuracy:\", np.mean(stamp_acc)) #0.544\n",
    "print(\"Circle IoU:\", np.mean(circle_iou), \"Circle Accuracy:\", np.mean(circle_acc)) #0.981\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
