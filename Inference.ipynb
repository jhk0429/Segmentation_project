{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "id": "ZgPEymw9njoY"
   },
   "outputs": [],
   "source": [
    "#path = 'saved_model_1001_1' #epoch 60 / 20  large image x3\n",
    "#path = 'saved_model_1001_softmax_RMSprop_80_30' Not bad, little noisy.\n",
    "#path = 'saved_model_1001_softmax_RMSprop_100_30_0.0001' #less noisy but stamp not really good\n",
    "#path = 'saved_models/saved_model_1001_softmax_RMSprop_100_40_0.0005' #less noisy. stamp better.\n",
    "#path = 'saved_model_1001_softmax_Adam_100_40_0.0005' #little bit worse\n",
    "#path = 'saved_model_1005_softmax_RMSprop_100_40_0.0005_with_classweights'\n",
    "#path = 'saved_model_1005_softmax_RMSprop_100_30_0.0005_B8_with_classweights'\n",
    "#path = 'saved_model_1005_softmax_RMSprop_50_30_0.0005_B16_with_classweights_100'\n",
    "#path = 'saved_model_1005_RMSprop_100_0.0005_B1_classweights_P5_S10'\n",
    "#path = 'saved_model_1005_RMSprop_80_0.0005_BNone_classweights_P5_S30'\n",
    "#path = 'saved_model_1006_Adam_70_0.0005_BNone_classweights_P5_S50'\n",
    "#path = 'saved_model_1006_RMSprop_70_0.0005_BNone_classweights_P86_S3055'\n",
    "#path = 'saved_model_1006_RMSprop_130_0.0005_BNone_classweights_P86_S3059'\n",
    "#path = 'saved_model_1006_RMSprop_150_0.0005_BNone_classweights_P86_S3056_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_0.0005_BNone_classweights_P86_S3056_EncoderTrained'\n",
    "path = 'saved_model_1006_RMSprop_100_0.0001_BNone_classweights_P86_S3057_EncoderTrained'\n",
    "#path = 'saved_model_1006_RMSprop_100_5e-05_BNone_classweights_P86_S3060_EncoderTrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXRm-jLtmzga",
    "outputId": "f7f57301-6e86-4cf3-deb6-f43f81a2829f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import segmentation_models as sm\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "KLDykGNHmkjU",
    "outputId": "9da2feff-35eb-478d-d052-7c9b2807464a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n  raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\\n\""
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (480,576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "id": "r0bNqPN0sR-1"
   },
   "outputs": [],
   "source": [
    "def display(display_list, idx=None, only_inference=False, fig_size=15):\n",
    "    \"\"\"\n",
    "    \"only_inference\" = True creates sample of inferenced image PNG file.\n",
    "    \"\"\"\n",
    "    if only_inference:\n",
    "        a = np.array(display_list)\n",
    "        a = a.astype(np.float32) * 255.0\n",
    "\n",
    "        cv2.imwrite(\"EX{}.png\".format(idx), cv2.cvtColor(a, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    else:\n",
    "        plt.figure(figsize=(fig_size,fig_size))\n",
    "        title = ['Ground Truth Mask', 'Pushed', 'Stamped']\n",
    "\n",
    "        for i in range(len(display_list)):\n",
    "            plt.subplot(1, len(display_list), i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "id": "l5OoNvjhsSYQ"
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask, num=0):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[num]\n",
    "\n",
    "def show_predictions(test_mode=False, x=None,y=None, num=1):\n",
    "    if test_mode:\n",
    "        print(\"In testing Mode...\")\n",
    "        for i in range(num):\n",
    "            pred_mask = model.predict(x, batch_size=1)\n",
    "            display([x[i], y[i], create_mask(pred_mask, num=i)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_and_count(img, contours, label = '', draw_type = 'contour', show=True):\n",
    "    # img : original image\n",
    "    # contours: Contours found from opencv code\n",
    "    assert label in ['push', 'stamp'], \"label must be either 'push' or 'stamp'\"\n",
    "    assert draw_type in ['bbox', 'contour'], \"draw type must be either 'bbox' or 'contour'\"\n",
    "    \n",
    "    if label=='push': val = 220\n",
    "    if label=='stamp': val = 150\n",
    "        \n",
    "    count = 0\n",
    "    area = []\n",
    "    width_height = []\n",
    "    \n",
    "    for idx, cnt in enumerate(contours):\n",
    "        a = cv2.contourArea(cnt)\n",
    "        if a < val:\n",
    "            continue\n",
    "        \n",
    "        area.append(a)\n",
    "        count += 1\n",
    "        \n",
    "        if draw_type == 'bbox':\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(125,125,0),2)\n",
    "            width_height.append([w,h])\n",
    "            print(\"{} #{} has width of {} and height of {}\".format(label, idx, w, h))\n",
    "            \n",
    "        elif draw_type == 'contour':\n",
    "            cv2.drawContours(img, [cnt], 0, (125, 125, 0), 2) \n",
    "            \n",
    "    if show:        \n",
    "        display([img], fig_size=8)\n",
    "        print(\"{} {} found. Area: {}\".format(count,label,area))\n",
    "\n",
    "        \n",
    "    return img, area, width_height, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twqjJGlpgxFv",
    "outputId": "c47d45d0-441e-4991-97b0-01f0e2b1108e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0, 0.0, 0.0], 1: [0.9607843, 0.5764706, 0.19215687], 2: [0.98039216, 0.19607843, 0.3254902], 3: [0.98039216, 0.98039216, 0.21568628]}\n"
     ]
    }
   ],
   "source": [
    "mask = imread('images/test/gt_mask/일반7__분리막 눌림_검정.png') #2048 x 2448\n",
    "\n",
    "colors = np.unique(tf.reshape(mask,[-1,3]), axis=0)\n",
    "\n",
    "color_dict = {i: list(x) for i,x in enumerate(colors)}\n",
    "print(color_dict)\n",
    "\n",
    "def rgb_to_onehot(rgb_arr, color_dict):\n",
    "    num_classes = len(color_dict)\n",
    "    shape = rgb_arr.shape[:2] + (num_classes,)\n",
    "    arr = np.zeros(shape, dtype=np.int8)\n",
    "    for i, cls in enumerate(color_dict):\n",
    "        arr[:, :, i] = np.all(rgb_arr.reshape((-1, 3)) == color_dict[i], axis=1).reshape(shape[:2])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHOUT TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "id": "RlUMjm41npRV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:04<00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  96.475 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "for idx,image in enumerate(tqdm(glob.glob(\"images/train/*/*.bmp\"))):\n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.resize(n, IMG_SIZE) #960,1152\n",
    "    \n",
    "    image = tf.expand_dims(image,0)\n",
    "    pred_mask.append(model(image)) # N, H, W, 3\n",
    "    \n",
    "    ex = pred_mask[idx][0] # H,W,4\n",
    "    \n",
    "    pushed = np.round(tf.expand_dims(ex[:,:,1], -1)) + np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    circle = np.round(tf.expand_dims(ex[:,:,3], -1))\n",
    "    stamped = np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    \n",
    "    stamped_x = stamped.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    closed_stamp = cv2.dilate(stamped_x, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(stamped_x, contours, label='stamp', show=False)\n",
    "    \n",
    "    pushed_x = pushed.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "    closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    push_img, push_area, wh, pushed_count = draw_and_count(pushed_x, contours, label='push', show=False)\n",
    "    \n",
    "    #print(\"Sample #{} has {} stamps and {} pushes. Stamp areas: {}, Push areas: {}\".format(idx, stamp_count, pushed_count, \n",
    "    #                                                                                 stamp_area, push_area))\n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \", (np.mean(time_list) * 1000).round(3), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "id": "hwMHOEtCqfvr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "model = tf.saved_model.load(path, tags=[trt.tag_constants.SERVING])\n",
    "graph_func = model.signatures[trt.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "frozen_func = trt.convert_to_constants.convert_variables_to_constants_v2(graph_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrWm1GYVtKvY",
    "outputId": "3ae00121-3d80-4657-aa5a-024b3b0948bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:03<00:00, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time is:  69.06 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "pred_mask = []\n",
    "\n",
    "img_loc = glob.glob(\"images/train/*/*.bmp\")\n",
    "    \n",
    "    \n",
    "for idx,image in enumerate(tqdm(img_loc)):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    n = cv2.imread(image)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    image = tf.image.resize(n, IMG_SIZE) #960,1152\n",
    "    \n",
    "    flipped = tf.image.flip_left_right(image)\n",
    "    \n",
    "    image = tf.expand_dims(flipped,0)\n",
    "    pred_mask.append(frozen_func(image)) # idx, 1, 1, H, W, 4\n",
    "    \n",
    "    ex = pred_mask[idx][0][0]\n",
    "    \n",
    "    pushed = np.round(tf.expand_dims(ex[:,:,1], -1)) + np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    circle = np.round(tf.expand_dims(ex[:,:,3], -1))\n",
    "    stamped = np.round(tf.expand_dims(ex[:,:,2], -1))\n",
    "    \n",
    "    # STAMP\n",
    "    stamped_x = stamped.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    closed_stamp = cv2.dilate(stamped_x, k)\n",
    "    contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    stamp_img, stamp_area, wh, stamp_count = draw_and_count(stamped_x, contours, label='stamp', show=False)\n",
    "    \n",
    "    # PUSH\n",
    "    pushed_x = pushed.astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "    closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    push_img, push_area, wh, pushed_count = draw_and_count(pushed_x, contours, label='push', show=False)\n",
    "\n",
    "\n",
    "    #print(\"Sample #{} has {} stamps and {} pushes. Stamp areas: {}, Push areas: {}\".format(idx, stamp_count, pushed_count, \n",
    "    #                                                                                  stamp_area, push_area))\n",
    "    \n",
    "    time_list.append(time.time()-start)\n",
    "    \n",
    "print(\"Average inference time is: \",(np.mean(time_list) * 1000).round(3), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH4GUMO4mcAD",
    "outputId": "96931dfc-beaa-47a5-efe8-492449956ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 480, 576, 3)\n",
      "(46, 480, 576, 1)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for img in glob.glob(\"images/train/*/*.bmp\"):\n",
    "    \n",
    "    n = cv2.imread(img)\n",
    "    n = tf.cast(n, tf.float32) / 255.0\n",
    "    n = tf.image.resize(n, IMG_SIZE) #960,1152\n",
    "\n",
    "    flipped = tf.image.flip_left_right(n)\n",
    "\n",
    "    train_x.append(flipped)\n",
    "\n",
    "    dir = \"/\".join(img.split(\"/\")[:-1]) + \"/gt_mask/\"\n",
    "    file_name = img.split(\"/\")[-1].split('.')[0]\n",
    "\n",
    "    y = imread(dir+file_name+\".png\")\n",
    "\n",
    "    a = rgb_to_onehot(y, color_dict) #change to one hot\n",
    "    \n",
    "    bb = tf.expand_dims(np.argmax(a, axis=-1),-1) #combine one hot #0,1,2,3\n",
    "    bbb = tf.image.resize(bb, IMG_SIZE) #960,1152\n",
    "    \n",
    "    flipped2 = tf.image.flip_left_right(bbb)\n",
    "\n",
    "    train_y.append(flipped2)\n",
    "\n",
    "test_x = tf.convert_to_tensor(train_x)\n",
    "test_y = tf.convert_to_tensor(train_y)\n",
    "\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZoMYAYb4Sv7"
   },
   "source": [
    "Ground truth numbers:\n",
    "1.   black_ng:\n",
    "1, 2/1, 3, 4, 4/2, 4/2, 3/1, 1, 1, 4/1\n",
    "3/3, 2, 4/1, 3/1\n",
    "2.   silver_ng:\n",
    "4, 4/1, 4/2, 3/1, 1, 1/1, 4/1,\n",
    "3/2, 2, 4, 2/1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAD8CAYAAAA2cEbpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAGyVJREFUeJzt3X+wpXddH/DPJ2TxB4RF3SgNgdiadipSe+vFsrGMqIVmDGDX6aIUK+BIM2w67dRif4jSXkBsB+sUpw6xaAsNFBRWu9g0dsnYIkWzTBu5oohlUoYUWAK7AQJNA6zk2z+e5yRn794f597znPM83+e8XjM7s/f8/N5z7vk8z/v5fJ/vyVJKAAAAMHyX9T0AAAAAZiPAAQAAVEKAAwAAqIQABwAAUAkBDgAAoBICHAAAQCUEOPYlMz+Smc/o8fk/lpnf1dfzT8vMZ2TmR/oeBzC/zHxXZr64o8fayMw3d/FYAIuWmd+YmSUzL+97LMxGgBuYzHxeZr43M+/PzE+1/78pM7Pvse0mM38zM/9v++9CZn5p6udfPOBjvjkzN+YY04vbgvSzWy7/G+3lv3zQxwb61R5MeqCtMZ/MzDdm5qP7HhewWjLzaZn5u5l5X2Z+OjN/JzO/PTNflJnv6Xt8jJMANyCZ+dKI+PmI+NmIeFxEfENEvCQi/kpEPHKH+zxiaQPcRSnle0spjy6lPDoi/kNEvGbycynlJVtvv8SjPHdFxPO2vE4vjIgPLen5gcV5Tltzvi0inhIRP9XzeIAVkpmPiYhbI+JfR8TXRsTjI+IVEfHFPsfF+AlwA5GZhyPilRFxUynlZCnl86XxvlLKD5VSvtje7o2ZeXNm3paZ90fEd2fm4cy8JTPPZebdmflTmXlZe/uLpvJsbZO304Ze1R4x+nxmvjMzj0zd/ofbx7w3M39yjt/vGe0R85dl5j0R8Utth+xdU7e5vB3bN2bmTRHxgxHxsvYI+3+cerhvy8w/aI92vTUzv2KXp/54RPyviHhG+xxXRsS3R8R/nnreyzLzZGbek5mfbV+Tb566/tmZ+cH29flYZv7YDr/jj2XmH2bmVft/hYCDKqV8PCJ+MyKevHWa93QNzMyvbDv797af9f+Rmd8w9VDX7FILj7ZH2T+bmb+fU1O5M/NPZ+Zvt/e7PSKOBLAK/lxERCnlraWUL5dSHiilvDMiLkTEL0bEde0+zGcjIjLzWZn5vsz8XGZ+dHqW0dT+2Y+0130mM1/SdvPe39aeX5i6/YvaevUL7f7QH2fmX526/nBm/tvM/ERmfjwzf3pyMDszH5GZ/zIzz2fmhyPiWUt5teiMADcc10XEV0TEO2a47fMj4tURcUVEvCeaIz+HI+LPRMTTI+IFEfEj+3ju57e3//poOn0/HhGRmU+KiJsj4ocj4qqI+LqIuHofj7vV1RHx6Ih4YkTctNsNSymvi4hfjYifabt43z919Q9ExDOj+X3X2/Ht5pZoXpOIiL8ZEb8eEV/acptbI+LPRtP5/MOIeNPUdW+IiB8tpVwREd8aEb+99Qky85UR8UMR8fRSytk9xgN0KDOfEBE3RMT79rjpC6OplU+Ipp69JCIemLp+p1r4+GgO+vx0NEfZfzwifq09IBQR8ZaIuDOa4Paq9nmA8ftQRHw5M/99Zn5vZn5NREQp5YPR1Jc72n2Yx7a3vz+a/ZHHRhOaTmTmsS2P+dRo9kd+MCJeGxE/Gc1B6G+JiB/IzKdvue3/jqb2/LOI+PXM/Nr2ujdGxJ9ExLUR8Zci4q9FxOQ8378dEc9uL39KRByf83VgyQS44TgSEedLKX8yuWDqaO8DmfmdU7d9Rynld0opD0ZzlOd5EfETbdfuIxHxc7F3qJn2hlLKh0opD0TE2yJirb38eETcWkp5d9sBfHlEPHjg37ApJBullC+1z3VQry2l3FNKuTea4LW2x+1/LSKekZlXRFM4b5m+spTyYCnlje3r94WI2IiI9cx8VHuTCxHxpMy8opTy6VLK703dPTPz56MJzt/TjglYjlPtke33RHNg5Wf2uP2FaILbte3R8jtLKZ+bun6nWvi3IuK2Usptbb24PSL+Z0TckJlPjKar//JSyhdLKe+OiP/U3a8IDFVbP54WESUifikizmXmb2zp7E/f/l2llD9o68j7I+Kt0ew/THtVKeULbSfv/oh4aynlU+1Mg/8eTeia+FQ0+0QXSim/Gs2Mo2e1z39DRPz9Usr9pZRPRcS/imZ/MaI5EP7aUspHSymfjoh/Pv+rwTIJcMNxb0Qcyalzw0op39Eetbk3Ln6vPjr1/yMRcSgi7p667O5o5mHP6p6p//+/aLpkEU3X7aHnKqXc347loD5ZStna+TqInca7rXbcpyPin0bEo0sp752+vp1K8JrM/HBmfi6a8+YiHp4G9f0R8X0R8X/a6ZVPnbr710VzROvVW3YEgcU7Vkp5bCnlmlLKTTMcGHpTNLXgVzLzbPu5PzR1/U615ZqIeG57QO2zbWh8WkT8qWjq5GfaOjMxXY+BESulfLCU8qJSytUR8eRoasJrt7ttZj41M/9bNqe83BdNl27rlOtPTv3/gW1+nt7n+XgppUz9fHf7/NdEs2/4iama9W+imV0QsWX/LtSs6ghww3FHNCe9/vUZbjv9YT0fzVHla6Yue2I0535FNEdvvnrqusftY0yfiGaqUUREZOZXRxNYDqps+XmvsW29/TxuiYiXxsVTIydeEM2Rqu+JZnrVte3lGRFRSnlvKeX7oil8t0bEr0zd93w04e7NmXm0w/ECB7NjXWmPUr+ilPKkiPiOaKYQvSD29tGIeFMbFif/HlVK+RfR1MmvmerYRzQ1GFgxpZQ/jmbq4pNj+32Yt0TEb0TEE0oph6M5T26eVcYfn3nRKuVPjIiz0dSsL0bEkama9ZhSyre0t7to/y7UrOoIcANRSvlsNCsXvS4zj2fmFe3iGmsR8ahd7vflaKb6vLq9zzUR8Q8iYrJwyWZEfGdmPjGbhVJ+Yh/DOhkRz85midxHRrPISpd/M78fEd+amX8hM78qmvnb0z4ZzXluXfiv0Zw397ptrrsimkJ3bzQ7fq+eXJGZX5WZz8/Mx5RSLkTE52PLNNJSym9FsxP4jsx8SkfjBQ5mM5qVZw+1n8eHzu3IzO9u680jIuJz0Rz8mmVa+Jsj4jmZeX3bsf/KzPyuzLy6lHJ3NNMpX5GZj8zMp0XEc7r/tYChycw/n5kvzcyr25+fEM259mei2Ye5ut1/mrgiIj5dSvlCZv7laM67ncfXR8Tfa+vdcyPim6OZ7v2JiHhnRPxcZj6m3Z/8pqnz597W3u/q9ry9fzLnOFgyAW5ASimviSZ8/aNoPvifjKbl/Y8j4nd3uevfjeao84ejORfkLRHx79rHvD2axUDeH81J9rfuYzwfiIi/0z7eJyLiMxHxsf38Tns8/h9Fc87Ku6KZt/3uLTf55Yj4i+1KTCfnfK4HSym/VUr5zDZXvyGaI1ZnI+IDcelr/cKIuLudXvmj0ZwPs/Xx/0s0JwXf2oZuoB8vj4hviqZevSKa+jXxuGgOTH0uIj4YzXlz23XlL1JK+Wg0syNeFhHnojm6/Q/j4W3o86NZTODT0RyIumWbhwHG5/PRfPbfm83K4GeiWQjtpdEcOP5ARNyTmefb298UEa/MzM9Hc1rH2+Z8/vdGs+DJ+WgOPh+fOhf/BdEsxvRH0dTDk9FM+45oztc7Hc2B9N+LZnE3KpIXT50FAACGLDNfFBEvLqU8re+xsHw6cAAAAJUQ4AAAACphCiUAAEAldOAAAAAqIcABAABU4vK+BxAR8czLnmseJ4zQ7Q++fZ4vKO2d2gTjVHttilCfYKxmqU86cAAAAJUQ4AAAACohwAEAAFRCgAMAAKiEAAcAAFAJAQ4AAKASAhwAAEAlBDgAAIBKCHAAAACVEOAAAAAqIcABAABUQoADAACohAAHAABQCQEOAACgEgIcAABAJQQ4AACASghwAAAAlRDgAAAAKiHAAQAAVEKAAwAAqIQABwAAUAkBDgAAoBICHAAAQCUEOAAAgEoIcAAAAJUQ4AAAACohwAEAAFTi8r4HwDidPrsZRzePx+Eb7nrosvtuuzbOrJ3c877rGyfiyOvvWOTwAACgSgIcnTp9dvOh/59ZOxlxdvra5rqjm8fjwqkrd32c8zded9HPh46d2zP8bQ2MALOYrlsHcf1Vax2NBAD2JsAxl/3s+KxvnDjw81w4dWWsn7r4/ndu3HzRz1sDo50qYC/zhrftHkPtAWCRBDhmMuv0x93cuXHzTN23WW0XCKdD3WSnys4UsEzTgU79AaBrWUrpewzxzMue2/8guEQXR6b3Mk9Xbi9bp106t275bn/w7dn3GOahNq2WZdS8CcGuX7XXpgj1CcZqlvokwHGRZe7AbLWoMLd1qmWEnadlqX0nSW1iYpG1UT1avtprU4T6BGM1S30yhZKI6De4TUwHrUVMtZx+/PM3XqcbB8xsOmR1XS9N9wZgPwS4FTaE0LaTM2snI7bZl5mnSzd930PHzsXpjU07TMC+LSrMOXcOgFmYQrmihhze9qOLaZd3btxsZ2lBap+mpDaxH13XVXVpcWqvTRHqE4yVc+C4xFiC207mmXopyHWv9p0ktYl5dVVz1aZu1V6bItQnGCvnwPGQsQe3iZ2mXkbs3a1b3zgRcWPzf+fHAV3YLngdpB6bXgnAhAA3cqsS3GZx58bNM0+5PH/jdREhyAHdmwSwg9ZnXxwOsNoEuBET3uY3CXLTK1jaWQK6MG+Qm7CKJcBqEeBGSHDb2X66cNOm73MkdOWA7nQd5KYfE4DxuazvAdAt4W1v232x9354jYFF6DJ0nT67qVYBjJQANxLnb7zOxnpJ1jdOeK2Bhei6c6ZWAYyPADcCp89uzt1VWjXzvl7rGyceOj8OoEtCHAC7EeAqZ8Pcr/tuu7bvIQAjJMQBsBMBrmI2yPPpomt54dSVQhxQBdsMgHEQ4CplQ9yNrkKc9wPo2iJWklSrAOonwFXGymLDZGEToBZqFUDdBLiK2OguRlcLwAhxQNcW9X1uahVAvQS4StjYLtadGzd3EuSEOKBr11+15ou5AXjI5X0PgL0JBMszHeLWN04c6DHWN07EkbijqyEBRMTD3biutgmnz24KhgAV0oGDHczTlbMyJbAoXXbkHCAEqI8AN3A2rv2bBLlDx87NfB8rUwKLNgly84Y5tQqgLqZQwozOrJ2MaPeTZpleub5xIuLGiCOvN50SWKytIU4oAxgvHbgBswEerq4WPQEYAtsbgHoIcANlY1qHWULc+RuvW8JIAB52kGmVtjsAdRDgBua+2661Ea3MLN04IQ5YNl8/ADBOAtzAnFk72fcQOKC9gpwQB/RhP0HOAUSA4RPgBsSGcxycGwcMkW4cwDgIcLAAO4W48zdeJ6gDvZklxKlRAMMmwA2EDeb47BTi1jdOmE4J9EYnDqBuAhwArJi9QpyDigDDJcANgA3leO12Ppz3HRgyNQpgmAS4ntlArq71jRPef6A3plIC1EmAAwC25SATwPAIcD2yYVwNu02j1IUD+qQLB1AfAQ6WYK8QB9AXIQ6gLgJcTywjzzRdOGCo1CeAYRHgerJbR4Zx8p4DQ6ULB1APAa4Hjmaurt2+3NvfBdAnIQ6gDgIcLJlOHDBUO4U4B5gAhkOAgx5sF+J04QAA2IsABwNydPN430MAVpyplADDJsBBT7brwl04daUuHNA7IQ5guAS4JbNzzrSdzofzNRPA0Nh+AQyDAAc92xri1jdOWOgE6N12XTghDqB/AtwS2fCxk0PHzvU9BAAAKiDAwQCcWTt5UdfNipSsEn/rADA7AW5J7KAwi+lOnBUpWQWT2qhGDpPFTACGR4CDATmzdvKh/184dWWPI4HFE9oAYP8EOBgYC5iwCrYLbwLdMG3twnmfAPolwC2BjR37NQlx/nYYI3/X9TGVEmA4BDgYKJ04xkh4q58wB9AvAW6FrG+c6HsIAFTq+qvWhDeAARDgVowQBwAA9RLgVoTgVq/7bru27yEAADAQAhwM3PRXCwAAsNoEuBWg+wYAAOMgwI3c0c3jl1wm0AEAQJ0EuAXrc8nso5vH48KpK3t7frpj6XUAACIEuNES3oChmeVAhIMVALA7AW4Etk6TFN4AAGCcBLgFWtaR5AunrnzovDbhDQAAxkuAG5H9hDcLmQDLcPrs5kP/9nMfAGB7AtyI6LwBQyKIAUD3BDgAOie8AcBiCHCVMxUSGCMBEAC2J8CtsO2+5BugC9dftdb3EABglAS4FeacOWCRhDgA6J4ABwAAUAkBDgAAoBICHAALYxolAHTr8r4HQHcOHTvnvDaAFTW9cqfgDDBeOnALZIl/AJZh69cu+BoGgPES4BboyOvv6HsILND6xgkhHejV6bObO4Y1IQ5gnAQ42Kejm8cvCm6+Tw92JkQAQLcEONiH9Y0Tl5xn6LxD6J5zuLohQAOMj0VMRsZCJoux11TJ9Y0TcefGzUsaDbDqBDOA1aUDt8IEjr3t5zw358MByyC8Aaw2HTjYwUEC2eQ+wjGwCAcJb6fPbl4yJXXr45iyClAPAW7Brr9qbWlHSy+cujIOHTs3020FjO111UXb+jheb5idMHGpebcjkxC324qVXneAOghwlbtz42ZT9zqyyNdRZw5mI0Q8rOuDf6ZeAoyDALeChIiLHd08vrSFX6ZDovcBGBJdOIA6CHAjM5lGuVMgERoe1nfnUlcO2E6fnTIhjlXlb5+aWIWSldR3eNsvGxVYDaY5ArAXAW4Etlu4ZLvLdHr297UAQ3L+xuv6HgKwYEMJb0MZBwDbM4VyCRa9EuWZtZOxfurhULLTapSr/GXTNYa2ifWNE3Hk9Xf0PQxgAYYalnYal9kAjJlplNRCB27F1Bxkxm677qD3C8ZrqOFtNzWOGfbD3zg1EOBGarfvhBMKhuXo5vFt3xPvE6vIztPweY8A+iXArahazwUbo60rhm59b0yfZNWcPrs5+pBQ++9X+/hhN/6+GToBbsRm+W4zIQ4AWHXXX7Xm/DeqIcAtyaKLwk6Lk+w0jXKaEAcM0Zg7cXYUATgoAW4FzBriBLnhMX2S2nURVMYc5IBhmdQsNYchE+BGbpZplNMEOWCoxhbkau7C1Tx2mNXYag7jIcAtUZ8bvFm6cNOEOKArdvYBoDsC3IjsdB7cfrtwE7pxwBA5Kg4sk3rD0AhwS1ZTF26i9hBX6/id/wa7s1PVDx1VVpF6w5AIcCPTdRcOoAt2+oFa+EoBhk6AWzGr2oUDxslR8eWyU8sq2fr3rt4wFAJcD/raAE66cKsU4mocc4Tpk4yTnf+6ef9AiGMYBLgR2mkaZReObh5f2GMDHIQdKgBWiQDXk0UfydzrXLiDduGcS7d4um+MmS7Ow2oKnt43VpW/fYZIgFtB84Y4gHksYoeopjAE1MW5cAyNANejvrpw04Q4gOUb0g6gFfdgbz4jDIkARxw6dk6QA1hRe4VJO65wqdNnNwd1IIbVIsD1rO8VKacJccCymEY5LF472Nt2dctnhz4IcCO32zTKC6euvCTIzRLial2avwYWMGGV6OwMn/cI9ibEsWwC3AD0fS7c1iCnEwcsS9f1r4YdqRrGCGxvp3NGTalkmQS4gRjCUc79hDhduO7pvgFAHXbabxPiWAYBbkXM2lXTiQMA2JtuHH0R4AZkkV24M2snZ/pagYiLp1TutkKlLlx3dN9YZas4jbIGQ5gZAjXQjWPZBLiBWcb5cKvUjath3MIb+C4yoG5qGMuUpZS+xxDPvOy5/Q9iYJZx1GY/HbRJENpu1cozayc7HdeyHN08vu3XKSzbmAPc7Q++PfsewzzUpv50UQOHvjM15KPzQ3/t5lV7bYpQn4Zu+vM99s8T3ZqlPglwA7XMDfusQe7QsXPbBp5Zp2YOVV9TQccc3CZq30lSm/q1CiFuN30FvJpfs1nVXpsi1KcabPcZXoXPF/OZpT6ZQjlQy/yA7+fcuO3Ufi5c7QEUxqqLKUlD7nIB4zapYdN1zAIndEGAG7Blh7h5gkztIW7ZVqH7Bl0R4pZHdwAWYzrM+ZwxLwFu4Jb9IZ83xAlyexPeYP/m3emZHPWuKcwtu/7bqQSogwBXgT5CnG7cYpiuCfPpoh7WFuSWQXgDqIcAV4k+Nq5CXPfsJMH8upqCJMQBUCOrUFZmCDsc+w1ntXSdlhE6V236ZO0rvalNdRj7apWLrvtD/t0XpfbaFKE+wVjNUp8uX8ZA6M71V631HuKmA9ks36W2vnGimhC3KKsW3GCZuqiLq/qdTav0uwKMhQ5chc7feN2gA9FOnawhj3liEV24VQ5vtR/lVpvqddBAN9RAs4gDd0P9XZeh9toUoT7BWPki75HruxN3EDV14+YNc4eOnYuIiMM33NXFcKpU+06S2sTQjH266LLUXpsi1CcYK1/kPXJHN4/3PYR9qyW8Rcw31js3bo4zaydXOrwB3Zs3fAlvAPUT4Cp2+Ia7bIwX7CBfqTC5vfcGWAS1BWC1WcRkBIawsMnYHTp2bs/FWqaDnh0sYJFmqfvqEMA4CXAjIcQt1pm1kxFr258XNwlu6xsnVnrBEmC5tqv7QhvA+JlCOSI23Is33WXbOr1SeAP6ZBsAsBp04EZGJ26xjm4ev+ScODtNQF/UH4DVowM3Qjbo3ZtMnTyzdvKiy73WAAAskwA3UoJFt7brunmNAQBYNgFuxASMxfC6AgDQF+fAjdx02HBu3MEJbQAADIEO3AoRQg7G6wYAwFAIcCtGGNkfrxcAAENiCuUKmoQSUyq3J7QBADBUOnArTFC5mJUlAQAYOh24FacbJ8gCAFAPAY6IWL3VKoU2AABqJMBxibGGOaENAIDaCXDsqvYwt75xIo68/o6+hwEAAJ0Q4JjZ1g7WkALd0c3jcfiGuy65/EgIbwAAjIcAx4H12Z3bGiYPx6XhDQAAxkaAoxNbA9V9t10bZ9ZOdvLYO3XXAABg1QhwLMThG+6K66ObRUN01wAAoOGLvAEAACohwAEAAFRCgAMAAKiEAAcAAFAJAQ4AAKASAhwAAEAlBDgAAIBKCHAAAACVEOAAAAAqIcABAABUQoADAACohAAHAABQCQEOAACgEgIcAABAJQQ4AACASghwAAAAlRDgAAAAKiHAAQAAVEKAAwAAqIQABwAAUAkBDgAAoBICHAAAQCUEOAAAgEoIcAAAAJUQ4AAAACohwAEAAFRCgAMAAKiEAAcAAFAJAQ4AAKASWUrpewwAAADMQAcOAACgEgIcAABAJQQ4AACASghwAAAAlRDgAAAAKiHAAQAAVEKAAwAAqIQABwAAUAkBDgAAoBICHAAAQCUEOAAAgEoIcAAAAJUQ4AAAACohwAEAAFRCgAMAAKiEAAcAAFAJAQ4AAKASAhwAAEAlBDgAAIBKCHAAAACVEOAAAAAqIcABAABUQoADAACoxP8HWRohfbjGcHEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc6348f940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3\n",
    "\n",
    "ex = np.round(pred_mask[idx][0][0]) # ex = H,W,4\n",
    "\n",
    "pushed = tf.expand_dims(ex[:,:,1], -1) + tf.expand_dims(ex[:,:,2], -1)\n",
    "circle = tf.expand_dims(ex[:,:,3], -1)\n",
    "stamped = tf.expand_dims(ex[:,:,2], -1) # stamped = H,W,1\n",
    "bg = tf.expand_dims(ex[:,:,0], -1)\n",
    "\n",
    "#bg = 0, pushed = 1, stamped = 2, circle = 3\n",
    "\n",
    "gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "#print((gt_mask==1).sum())\n",
    "\n",
    "display([gt_mask, pushed, stamped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "0QwwNKUVIyoR",
    "outputId": "1e6e11aa-bf65-47f6-dee0-a87dd665ab29"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc6345dda0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 stamp found. Area: [1177.5]\n"
     ]
    }
   ],
   "source": [
    "stamped_x = np.array(stamped).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "closed_stamp = cv2.dilate(stamped_x, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closed_stamp, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(stamped_x, contours, label=\"stamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "6hnpBdTNLnnt",
    "outputId": "3fdb3c92-53a0-4dae-85af-e56ff3e6e46d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc63779cf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 push found. Area: [9315.0, 5781.0, 3667.0]\n"
     ]
    }
   ],
   "source": [
    "pushed_x = np.array(pushed).astype(np.uint8) * 255\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))\n",
    "closing = cv2.morphologyEx(pushed_x, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "img, area, wh, count = draw_and_count(pushed_x, contours, label='push', draw_type='contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchannel_0 = np.zeros((480,576,1)) #prediction\\nchannel_1 = np.zeros((480,576,1))\\nchannel_2 = np.zeros((480,576,1))\\n\\nchannel_0[pushed==1] = color_dict[1][0]\\nchannel_1[pushed==1] = color_dict[1][1]\\nchannel_2[pushed==1] = color_dict[1][2]\\n\\nchannel_0[circle==1] = color_dict[3][0]\\nchannel_1[circle==1] = color_dict[3][1]\\nchannel_2[circle==1] = color_dict[3][2]\\n\\nchannel_0[stamped==1] = color_dict[2][0]\\nchannel_1[stamped==1] = color_dict[2][1]\\nchannel_2[stamped==1] = color_dict[2][2]\\n\\nchannel_0[bg==1] = color_dict[0][0]\\nchannel_1[bg==1] = color_dict[0][1]\\nchannel_2[bg==1] = color_dict[0][2]\\n\\ncom = tf.concat([channel_0, channel_1, channel_2], -1)\\n'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "channel_0 = np.zeros((480,576,1)) #prediction\n",
    "channel_1 = np.zeros((480,576,1))\n",
    "channel_2 = np.zeros((480,576,1))\n",
    "\n",
    "channel_0[pushed==1] = color_dict[1][0]\n",
    "channel_1[pushed==1] = color_dict[1][1]\n",
    "channel_2[pushed==1] = color_dict[1][2]\n",
    "\n",
    "channel_0[circle==1] = color_dict[3][0]\n",
    "channel_1[circle==1] = color_dict[3][1]\n",
    "channel_2[circle==1] = color_dict[3][2]\n",
    "\n",
    "channel_0[stamped==1] = color_dict[2][0]\n",
    "channel_1[stamped==1] = color_dict[2][1]\n",
    "channel_2[stamped==1] = color_dict[2][2]\n",
    "\n",
    "channel_0[bg==1] = color_dict[0][0]\n",
    "channel_1[bg==1] = color_dict[0][1]\n",
    "channel_2[bg==1] = color_dict[0][2]\n",
    "\n",
    "com = tf.concat([channel_0, channel_1, channel_2], -1)\n",
    "\"\"\"\n",
    "\n",
    "#display(com, idx, only_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background IoU: 0.9876946 Background Accuracy: 0.995884\n",
      "Push IoU: 0.6679955 Push Accuracy: 0.41133097\n",
      "Stamp IoU: 0.54008263 Stamp Accuracy: 0.102555335\n",
      "Circle IoU: 0.98253965 Circle Accuracy: 0.98730356\n"
     ]
    }
   ],
   "source": [
    "def class_iou(gt_mask, prediction, cls = 0, metric = 'iou'):\n",
    "    \"\"\"\n",
    "    Returns IoU score if metric == 'iou', Accuracy if metric == 'acc'\n",
    "    Accuracy not recommended for evaluating segmentation task\n",
    "    \"\"\"\n",
    "    a = np.zeros(IMG_SIZE + (1,))\n",
    "    b = np.zeros(IMG_SIZE + (1,))\n",
    "    \n",
    "    a[gt_mask==cls] = 1\n",
    "    b[prediction==1] = 1\n",
    "    \n",
    "    if metric == 'iou':\n",
    "        iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "        iou.update_state(a, b)\n",
    "        return(iou.result().numpy())\n",
    "    \n",
    "    elif metric == 'acc':\n",
    "        m = tf.keras.metrics.Accuracy()\n",
    "\n",
    "        weight = np.zeros(a.shape)\n",
    "        weight[gt_mask==cls] = 1\n",
    "\n",
    "        m.update_state(a, b, sample_weight = weight)\n",
    "    \n",
    "        return(m.result().numpy())\n",
    "\n",
    "\n",
    "bg_iou = []\n",
    "push_iou = []\n",
    "stamp_iou = []\n",
    "circle_iou = []\n",
    "\n",
    "bg_acc = []\n",
    "push_acc = []\n",
    "stamp_acc = []\n",
    "circle_acc = []\n",
    "\n",
    "for idx in range(46):\n",
    "    ex = np.round(pred_mask[idx][0][0]) # ex = H,W,4\n",
    "    \n",
    "    prediction = np.zeros(IMG_SIZE + (1,))\n",
    "\n",
    "    pushed = tf.expand_dims(ex[:,:,1], -1) + tf.expand_dims(ex[:,:,2], -1)\n",
    "    circle = tf.expand_dims(ex[:,:,3], -1)\n",
    "    stamped = tf.expand_dims(ex[:,:,2], -1) # stamped = H,W,1\n",
    "    bg = tf.expand_dims(ex[:,:,0], -1)\n",
    "\n",
    "    gt_mask = np.round(test_y[idx],decimals = 0)\n",
    "    \n",
    "    prediction[pushed==1] = 1\n",
    "    prediction[stamped==1] = 2\n",
    "    prediction[circle==1] = 3\n",
    "    prediction[bg==1] = 0\n",
    "    \n",
    "    bg_acc.append(class_iou(gt_mask, bg, metric='acc'))\n",
    "    push_acc.append(class_iou(gt_mask, pushed, cls=1, metric='acc'))\n",
    "    stamp_acc.append(class_iou(gt_mask, stamped, cls=2, metric='acc'))\n",
    "    circle_acc.append(class_iou(gt_mask, circle, cls=3, metric='acc'))\n",
    "    \n",
    "    bg_iou.append(class_iou(gt_mask,bg))\n",
    "    push_iou.append(class_iou(gt_mask,pushed,cls=1))\n",
    "    stamp_iou.append(class_iou(gt_mask,stamped,cls=2))\n",
    "    circle_iou.append(class_iou(gt_mask,circle,cls=3))\n",
    "    \n",
    "print(\"Background IoU:\", np.mean(bg_iou), \"Background Accuracy:\", np.mean(bg_acc)) #0.986\n",
    "print(\"Push IoU:\", np.mean(push_iou), \"Push Accuracy:\", np.mean(push_acc)) #0.664\n",
    "print(\"Stamp IoU:\", np.mean(stamp_iou), \"Stamp Accuracy:\", np.mean(stamp_acc)) #0.544\n",
    "print(\"Circle IoU:\", np.mean(circle_iou), \"Circle Accuracy:\", np.mean(circle_acc)) #0.981\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
